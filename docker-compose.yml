version: "3.9"

services:
  receipt-ai:
    build:
      context: .
      dockerfile: Dockerfile
    image: receipt-ai:latest
    container_name: receipt-ai
    restart: unless-stopped

    environment:
      # ── Required ───────────────────────────────────────────────────────────
      PAPERLESS_URL:   ${PAPERLESS_URL}
      PAPERLESS_TOKEN: ${PAPERLESS_TOKEN}
      OLLAMA_URL:      ${OLLAMA_URL:-http://host.docker.internal:11434}

      # ── Models (must match names in `ollama list`) ─────────────────────────
      VISION_MODEL: ${VISION_MODEL:-llava}
      TEXT_MODEL:   ${TEXT_MODEL:-mistral}

      # ── App behaviour ──────────────────────────────────────────────────────
      DATABASE_PATH: /data/receipts.db
      LOG_LEVEL:     ${LOG_LEVEL:-INFO}
      BATCH_HOUR:    ${BATCH_HOUR:-2}

      # Model cache directories - persist across rebuilds via volume mount
      HF_HOME: /root/.cache/huggingface
      TRANSFORMERS_CACHE: /root/.cache/huggingface/transformers
      PADDLEOCR_CACHE_DIR: /root/.cache/paddleocr

    volumes:
      - /mnt/cache/appdata/receipt-ai/data:/data
      - /mnt/cache/appdata/receipt-ai/logs:/logs
      # Model cache volumes - persist across rebuilds
      - /mnt/cache/appdata/receipt-ai/models:/root/.cache

    ports:
      - "3030:8000"       # UI + API both on port 3030

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

    extra_hosts:
      - "host.docker.internal:host-gateway"   # reach Ollama on host network
